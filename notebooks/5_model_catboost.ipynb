{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2cba9c",
   "metadata": {},
   "source": [
    "# CatBoost Model Development\n",
    "\n",
    "This notebook demonstrates the development of a CatBoost model for predicting blend properties. CatBoost is a high-performance open-source library for gradient boosting on decision trees. It is particularly effective in handling categorical features and provides state-of-the-art accuracy.\n",
    "\n",
    "Here's a breakdown of what we'll cover:\n",
    "\n",
    "1.  **Data Loading:** Loading the processed training, validation, and test datasets.\n",
    "2.  **Hyperparameter Tuning & Model Training:** Using Optuna to find the optimal hyperparameters for the CatBoost model and training the model on the combined training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7659b68",
   "metadata": {},
   "source": [
    "### 1. Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c66d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory where the processed data is stored\n",
    "data_path = Path(\"../processed_data\")\n",
    "\n",
    "# Load the training and validation datasets\n",
    "X_train, X_val, y_train, y_val = (\n",
    "    pd.read_csv(data_path / \"X_train.csv\"),\n",
    "    pd.read_csv(data_path / \"X_val.csv\"),\n",
    "    pd.read_csv(data_path / \"y_train.csv\"),\n",
    "    pd.read_csv(data_path / \"y_val.csv\")\n",
    ")\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "print(f\"train shape: {X_train.shape}\")\n",
    "print(f\"val shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20e60c",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter Tuning & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial: optuna.Trial, X_train: pd.DataFrame, y_train: pd.Series, X_val: pd.DataFrame, y_val: pd.Series):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize.\n",
    "    This function trains a CatBoost model with a set of hyperparameters\n",
    "    suggested by Optuna and returns the cross-validated MAPE.\n",
    "\n",
    "    Parameters:\n",
    "      trial (optuna.Trial): An Optuna trial object that suggests hyperparameters.\n",
    "      X (pd.DataFrame): Feature matrix for training.\n",
    "      y (pd.Series): Target variable for training.\n",
    "\n",
    "    Returns:\n",
    "      float: The mean absolute percentage error (MAPE) of the model on the validation set during cross-validation.\n",
    "    \"\"\"\n",
    "    # Define the hyperparameter search space for CatBoost\n",
    "    param = {\n",
    "        'objective': 'MAPE',\n",
    "        'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 3, 8),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 10),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model and evaluate using the validation set\n",
    "    model = cb.CatBoostRegressor(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)\n",
    "    preds = model.predict(X_val)\n",
    "    mape = mean_absolute_percentage_error(y_val, preds)\n",
    "\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the directory for saving models and Optuna studies\n",
    "model_dir = Path(\"../models/catboost\")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "optuna_dir = Path(\"../optuna_db\")\n",
    "optuna_dir.mkdir(parents=True, exist_ok=True)\n",
    "storage_name = f\"sqlite:///{optuna_dir}/catboost_studies.db\"\n",
    "\n",
    "# Dictionary to store the best models\n",
    "best_models = {}\n",
    "\n",
    "# Iterate over each target property to tune and train a model\n",
    "for target in y_train.columns:\n",
    "    print(f\"\\n--- Tuning and Training for {target} ---\\n\")\n",
    "\n",
    "    # Create an Optuna study to find the best hyperparameters\n",
    "    study = optuna.create_study(direction='minimize',\n",
    "                                study_name='catboost-tuning-' + target,\n",
    "                                storage=storage_name,\n",
    "                                load_if_exists=True)\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train[target], X_val, y_val[target]), n_trials=50)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    print(f\"\\nBEST MAPE FOR {target}: {study.best_value}\")\n",
    "    print(f\"BEST HYPERPARAMETERS FOR {target}: {best_params}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters on the entire training set\n",
    "    final_model = cb.CatBoostRegressor(**best_params, random_state=42, verbose=0)\n",
    "    final_model.fit(X_train, y_train[target])\n",
    "\n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(final_model, f'{model_dir}/{target}_model.joblib')\n",
    "    print(f\"Saved best model for {target}\")\n",
    "\n",
    "    # Store the best model with its MAPE score in the dictionary\n",
    "    best_models[target] = (final_model, study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
